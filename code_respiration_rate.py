# -*- coding: utf-8 -*-
"""Code_Respiration_Rate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gk-rrMdc8Q_gyBSSHTsxDw8mSmzvygY8
"""

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, Add, LeakyReLU,Conv1D, Conv1DTranspose
from tensorflow.keras.models import Model
from tensorflow.keras.losses import MeanAbsoluteError
from scipy.signal import resample
from tqdm import tqdm
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers.legacy import Adam

from google.colab import drive
drive.mount('/content/drive')

#downsampling shape
data_dir = '/content/drive/MyDrive/bidmc_csv-20230924T070751Z-001/bidmc_csv'
#data_dir = '/content/drive/MyDrive/bidmc_csv'

patient_id = 1
signal_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv-20230924T070751Z-001/bidmc_csv/bidmc_{patient_id:02d}_Signals.csv'))
#signal_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv/bidmc_{patient_id:02d}_Signals.csv'))

ppg_signals = signal_data[' PLETH'].values  # Assuming 'PLETH' column contains PPG signals
respiratory_signals = signal_data[' RESP'].values  # Assuming 'RESP' column contains respiratory signals

    # Down-sample to 30 Hz
desired_sample_rate = 30
original_sample_rate = 125


resampling_factor = desired_sample_rate / original_sample_rate


ppg_signals = resample(ppg_signals, int(len(ppg_signals) * resampling_factor))
respiratory_signals = resample(respiratory_signals, int(len(respiratory_signals) * resampling_factor))


ppg_signals = (ppg_signals - np.min(ppg_signals)) / (np.max(ppg_signals) - np.min(ppg_signals))
respiratory_signals = (respiratory_signals - np.min(respiratory_signals)) / (np.max(respiratory_signals) - np.min(respiratory_signals))
print(np.shape(ppg_signals))

window_size = 30 * desired_sample_rate


frames = len(ppg_signals) // window_size


ppg_signals_reshaped = ppg_signals[:frames * window_size].reshape((frames, window_size, 1))


respiratory_signals_reshaped = respiratory_signals[:frames * window_size].reshape((frames, window_size, 1))


ppg_signals_reshaped = (ppg_signals_reshaped - np.min(ppg_signals_reshaped)) / (np.max(ppg_signals_reshaped) - np.min(ppg_signals_reshaped))
respiratory_signals_reshaped = (respiratory_signals_reshaped - np.min(respiratory_signals_reshaped)) / (np.max(respiratory_signals_reshaped) - np.min(respiratory_signals_reshaped))

print(np.shape(ppg_signals_reshaped))

import matplotlib.pyplot as plt


plt.figure(figsize=(12, 6))
plt.subplot(2, 1, 1)
plt.plot(ppg_signals, label='PPG Signals')
plt.title('PPG Signals')
plt.xlabel('Time')
plt.ylabel('Amplitude')
plt.legend()


plt.subplot(2, 1, 2)
plt.plot(respiratory_signals, label='Respiratory Signals', color='r')
plt.title('Respiratory Signals')
plt.xlabel('Time')
plt.ylabel('Amplitude')
plt.legend()

plt.tight_layout()
plt.show()

def build_generator(input_shape, output_shape):
    inputs = Input(shape=input_shape)
    x = Conv1D(64, kernel_size=3, padding='same', activation='relu')(inputs)
    x = Conv1D(128, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(512, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(512, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)
    outputs = Conv1D(output_shape[-1], kernel_size=3, padding='same', activation='sigmoid')(x)
    return Model(inputs, outputs)

def build_discriminator(input_shape):
    inputs = Input(shape=input_shape)
    x = Conv1D(64, kernel_size=3, padding='same', activation='relu')(inputs)
    x = Conv1D(128, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(512, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(512, kernel_size=3, padding='same', activation='relu')(x)
    x = Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)
    outputs = Conv1D(1, kernel_size=3, padding='same', activation='sigmoid')(x)
    return Model(inputs, outputs)



# Load and preprocess the dataset for a single patient
def load_and_preprocess_patient_data(patient_id, data_dir):
    breaths_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv-20230924T070751Z-001/bidmc_csv/bidmc_{patient_id:02d}_Breaths.csv'))
    numerics_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv-20230924T070751Z-001/bidmc_csv/bidmc_{patient_id:02d}_Numerics.csv'))
    signal_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv-20230924T070751Z-001/bidmc_csv/bidmc_{patient_id:02d}_Signals.csv'))
    #breaths_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv/bidmc_{patient_id:02d}_Breaths.csv'))
    #numerics_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv/bidmc_{patient_id:02d}_Numerics.csv'))
    #signal_data = pd.read_csv(os.path.join(data_dir, f'/content/drive/MyDrive/bidmc_csv/bidmc_{patient_id:02d}_Signals.csv'))


    ppg_signals = signal_data[' PLETH'].values
    respiratory_signals = signal_data[' RESP'].values

    desired_sample_rate = 30
    original_sample_rate = 125

    resampling_factor = desired_sample_rate / original_sample_rate

    ppg_signals = resample(ppg_signals, int(len(ppg_signals) * resampling_factor))
    respiratory_signals = resample(respiratory_signals, int(len(respiratory_signals) * resampling_factor))

    window_size = 30 * desired_sample_rate

    frames = len(ppg_signals) // window_size

    ppg_signals_reshaped = ppg_signals[:frames * window_size].reshape((frames, window_size, 1))

    respiratory_signals_reshaped = respiratory_signals[:frames * window_size].reshape((frames, window_size, 1))

    ppg_signals_reshaped = (ppg_signals_reshaped - np.min(ppg_signals_reshaped)) / (np.max(ppg_signals_reshaped) - np.min(ppg_signals_reshaped))
    respiratory_signals_reshaped = (respiratory_signals_reshaped - np.min(respiratory_signals_reshaped)) / (np.max(respiratory_signals_reshaped) - np.min(respiratory_signals_reshaped))

    processed_data = {'PPG': ppg_signals_reshaped, 'Respiratory': respiratory_signals_reshaped}

    return processed_data

from sklearn.model_selection import GroupKFold

if __name__ == "__main__":
    data_dir = '/content/drive/MyDrive/bidmc_csv-20230924T070751Z-001/bidmc_csv'
    #data_dir = '/content/drive/MyDrive/bidmc_csv'
    num_patients = 53

    all_processed_ppg = []
    all_processed_respiratory = []
    patient_ids = []

    for patient_id in range(1, num_patients + 1):
        processed_data = load_and_preprocess_patient_data(patient_id, data_dir)

        data_X = processed_data['PPG']
        data_Y = processed_data['Respiratory']

        num_samples = len(data_X)
        data_X = data_X.reshape(num_samples, -1, 1)
        data_Y = data_Y.reshape(num_samples, -1, 1)

        all_processed_ppg.append(data_X)
        all_processed_respiratory.append(data_Y)
        patient_ids.extend([patient_id] * len(data_X))

    concatenated_ppg = np.concatenate(all_processed_ppg, axis=0)
    concatenated_respiratory = np.concatenate(all_processed_respiratory, axis=0)


    num_folds = 5
    gkf = GroupKFold(n_splits=num_folds)

    fold = 1
    for train_index, test_index in gkf.split(concatenated_ppg, groups=patient_ids):

        train_X, test_X = concatenated_ppg[train_index], concatenated_ppg[test_index]
        train_Y, test_Y = concatenated_respiratory[train_index], concatenated_respiratory[test_index]

        print(f"Fold {fold} - Train data shape: {train_X.shape}, Test data shape: {test_X.shape}")

        fold += 1

from sklearn.model_selection import GroupKFold
import numpy as np

def train_cycle_gan(data_X, data_Y, epochs, batch_size):
    input_shape = data_X.shape[1:]
    generator_XY = build_generator(input_shape, data_Y.shape[1:])
    generator_YX = build_generator(input_shape, data_X.shape[1:])

    discriminator_X = build_discriminator(input_shape)
    discriminator_Y = build_discriminator(input_shape)

    generator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)
    discriminator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)

    generator_XY.compile(optimizer=generator_optimizer, loss='mean_absolute_error')
    generator_YX.compile(optimizer=generator_optimizer, loss='mean_absolute_error')
    discriminator_X.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')
    discriminator_Y.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')

    dataset = tf.data.Dataset.from_tensor_slices((data_X, data_Y)).batch(batch_size)
    # real_labels = tf.ones((batch_X.shape[0], 1))
    # fake_labels = tf.zeros((batch_X.shape[0], 1))
    for epoch in range(epochs):
        with tqdm(total=len(data_X)//batch_size, desc=f'Epoch {epoch+1}') as pbar:
            for batch_X, batch_Y in dataset:
                fake_Y = generator_XY.predict(batch_X)
                fake_X = generator_YX.predict(batch_Y)
                real_labels = tf.ones((batch_X.shape[0], 1))
                fake_labels = tf.zeros((batch_X.shape[0], 1))

                dX_loss_real = discriminator_X.train_on_batch(batch_X, real_labels)
                dY_loss_real = discriminator_Y.train_on_batch(batch_Y, real_labels)
                dX_loss_fake = discriminator_X.train_on_batch(fake_X, fake_labels)
                dY_loss_fake = discriminator_Y.train_on_batch(fake_Y, fake_labels)

                gXY_loss = generator_XY.train_on_batch(batch_X, batch_Y)
                gYX_loss = generator_YX.train_on_batch(batch_Y, batch_X)

                pbar.update(1)

    return generator_XY
        # Print loss for this epoch
                  #print(f'Epoch {epoch + 1}, dX_loss_real: {dX_loss_real}, dY_loss_real: {dY_loss_real}, '
              #f'dX_loss_fake: {dX_loss_fake}, dY_loss_fake: {dY_loss_fake}, '
             # f'gXY_loss: {gXY_loss}, gYX_loss: {gYX_loss}')

# Define a function to evaluate the CycleGAN model
#def evaluate_cycle_gan(test_X, test_Y):
    # Evaluation code for CycleGAN here
    # Use test_X and test_Y for evaluation

def evaluate_cycle_gan(generator_XY, test_X, test_Y):

    synthetic_respiratory_signals = generator_XY.predict(test_X)

    absolute_errors = np.abs(synthetic_respiratory_signals - test_Y)

    mae = np.mean(absolute_errors)

    return mae

if __name__ == "__main__":
    data_dir = '/content/drive/MyDrive/bidmc_csv'
    num_patients = 53

    all_processed_ppg = []
    all_processed_respiratory = []
    patient_ids = []
    mae_values = []

    for patient_id in range(1, num_patients + 1):
        processed_data = load_and_preprocess_patient_data(patient_id, data_dir)

        data_X = processed_data['PPG']
        data_Y = processed_data['Respiratory']

        num_samples = len(data_X)
        data_X = data_X.reshape(num_samples, -1, 1)
        data_Y = data_Y.reshape(num_samples, -1, 1)


        all_processed_ppg.append(data_X)
        all_processed_respiratory.append(data_Y)
        patient_ids.extend([patient_id] * len(data_X))

    concatenated_ppg = np.concatenate(all_processed_ppg, axis=0)
    concatenated_respiratory = np.concatenate(all_processed_respiratory, axis=0)

    num_folds = 5
    gkf = GroupKFold(n_splits=num_folds)

    fold = 1
    for train_index, test_index in gkf.split(concatenated_ppg, groups=patient_ids):
        train_X, test_X = concatenated_ppg[train_index], concatenated_ppg[test_index]
        train_Y, test_Y = concatenated_respiratory[train_index], concatenated_respiratory[test_index]


        generator_XY=train_cycle_gan(train_X, train_Y, epochs=20, batch_size=32)

        mae = evaluate_cycle_gan(generator_XY, test_X, test_Y)
        mae_values.append(mae)

        print(f"Fold {fold} - Training and evaluation completed. MAE: {mae}")

        fold += 1


    average_mae = np.mean(mae_values)
    print(f"Average MAE across {num_folds} folds: {average_mae}")

total_samples = len(test_X)
print("Total number of samples:", total_samples)

sample_index = 0

sample_shape = test_X[sample_index].shape

print("Shape of sample at index", sample_index, ":", sample_shape)

import matplotlib.pyplot as plt
import numpy as np


sample_index = 159
synthetic_signal = generator_XY.predict(test_X)[sample_index].flatten()
original_signal = test_Y[sample_index].flatten()

synthetic_signal = synthetic_signal * (np.max(original_signal) - np.min(original_signal)) + np.min(original_signal)

synthetic_signal = np.clip(synthetic_signal, 0.0, 1.0)

mae = np.mean(np.abs(synthetic_signal - original_signal))

print("Mean Absolute Error (MAE):", mae)

time_axis = np.arange(len(original_signal)) / desired_sample_rate

plt.figure(figsize=(10, 6))
plt.plot(time_axis, original_signal, label='Original Respiratory Signal', color='b')
plt.plot(time_axis, synthetic_signal, label='Synthetic Respiratory Signal', color='r', linestyle='dashed')
plt.title('Comparison of Original and Synthetic Respiratory Signals')
plt.xlabel('Time (seconds)')
plt.ylabel('Amplitude')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

sample_index = 159


synthetic_signal = generator_XY.predict(test_X)[sample_index].flatten()
original_signal = test_Y[sample_index].flatten()

synthetic_signal = synthetic_signal * (np.max(original_signal) - np.min(original_signal)) + np.min(original_signal)

synthetic_signal = np.clip(synthetic_signal, 0.0, 1.0)

mae = np.mean(np.abs(synthetic_signal - original_signal))


print("Mean Absolute Error (MAE):", mae)


time_axis = np.arange(len(original_signal)) / desired_sample_rate

plt.figure(figsize=(10, 6))
plt.plot(time_axis, original_signal, label='Original Respiratory Signal', color='b')
plt.title('Original Respiratory Signal')
plt.xlabel('Time (seconds)')
plt.ylabel('Amplitude')
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(time_axis, synthetic_signal, label='Synthetic Respiratory Signal', color='r', linestyle='dashed')
plt.title('Synthetic Respiratory Signal')
plt.xlabel('Time (seconds)')
plt.ylabel('Amplitude')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

sample_index = 0


synthetic_signal = generator_XY.predict(test_X)[sample_index].flatten()
original_signal = test_Y[sample_index].flatten()


synthetic_signal = synthetic_signal * (np.max(original_signal) - np.min(original_signal)) + np.min(original_signal)

synthetic_signal = np.clip(synthetic_signal, 0.0, 1.0)


time_axis = np.arange(len(original_signal)) / desired_sample_rate

plt.figure(figsize=(10, 6))
plt.plot(time_axis, original_signal, label='Original Respiratory Signal', color='b')
plt.plot(time_axis, synthetic_signal, label='Synthetic Respiratory Signal', color='r', linestyle='dashed')
plt.title('Comparison of Original and Synthetic Respiratory Signals')
plt.xlabel('Time (seconds)')
plt.ylabel('Amplitude')
plt.legend()
plt.show()